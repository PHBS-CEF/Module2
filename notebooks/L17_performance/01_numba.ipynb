{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f433b0f9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# High performance Python code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5d8f3f",
   "metadata": {},
   "source": [
    "The two biggest benefits of Python are:\n",
    "\n",
    "1. Optimized for readability which makes reading/writing code relatively easy\n",
    "2. Incredible ecosystem of packages that have developed around vanilla Python\n",
    "\n",
    "but one of the trade-offs that has historically been made by Python developers is that they are forced to write C/Fortran/CUDA code in order to achieve maximum performance. There have been a number of advances that make this much less true today than it was 5 or 10 years ago.\n",
    "\n",
    "We will talk about two these advances:\n",
    "\n",
    "* Just in time (JIT) compilation\n",
    "* More support within Python for specialized hardware like GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99a0f8a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Numba (CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263cb978",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Pieces of this section were taken from the [QuantEcon lecture on Numba](https://python-programming.quantecon.org/numba.html).\n",
    "\n",
    "If you'd like to know more about these tools, we recommend reading the QuantEcon lecture and the (very good) [Numba documentation](https://numba.readthedocs.io/en/stable/index.html#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caeaf03",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numba\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f855568a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Compiled vs Interpreted\n",
    "\n",
    "You may have heard about the differences between \"compiled programming languages\" and \"interpreted programming languages\"\n",
    "\n",
    "* A compiled language is run in a few steps:\n",
    "  1. Programmer writes the code\n",
    "  2. Compiler converts that code into machine code\n",
    "  3. Computer runs machine code. Note that once the code is compiled, it can be run whenever one wants without the compilation step\n",
    "* An interpreted language runs code differently:\n",
    "  1. Programmer writes code\n",
    "  2. Computer \"runs\" the code by\n",
    "    * An \"interpreter\" reads the code line-by-line\n",
    "    * For each line, the interpreter figures out what the inputs are and tries to convert it to machine code\n",
    "    * Computer runs the machine code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e64014",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Pros and cons of compiled**\n",
    "\n",
    "* Once the compiler has run, the code is already machine code and runs very fast (as fast as possible given the code you wrote)\n",
    "* For very large programs, compilation requires the upfront cost of compilation which can take minutes/hours\n",
    "* Compiled programs can only be shared within similar hardware architecture and operating systems (though as long as there's a compiler for the hardware/OS, one could recompile the code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284d0295",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Pros and cons of interpreted**\n",
    "\n",
    "* As long as there is an interpreter for the hardware/operating system, interpreted code can be easily shared\n",
    "* Significantly slower than compiled code because of the back and forth to read the code line-by-line (which has to be redone each time the code is run!)\n",
    "* Easier to interact with your code (and more importantly, your data!) because you can run one line at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2d6ccd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Just-in-time compiled (JIT)\n",
    "\n",
    "JIT is a relatively modern development which has the goal of bridging some of the gaps between compiled and interpreted.\n",
    "\n",
    "Rather than compile the code ahead of time or interpreting line-by-line, JIT compiles small chunks of the code right before it runs them.\n",
    "\n",
    "For example, imagine that we have a function `mc_approximate_pi` that approximates the value of pi using Monte-carlo methods... We might even want to run this function multiple times to average across the approximations. The way JIT works is,\n",
    "\n",
    "1. Check the input types to the function\n",
    "2. The first time it sees particular types of inputs to the function, it compiles the function assuming those types as inputs and stores this compiled code\n",
    "3. The computer then runs the function using the compiled code -- If it has seen these inputs before, it can jump directly to this step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daad0d9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Our favorite JIT tools\n",
    "\n",
    "* `Numba`: [Numba](https://numba.pydata.org/) is a package built for Python that adds JIT compilation capabilities for a subset of the Python programming languages -- The priority has been tools for scientific computing `numpy` etc... The main drawback is that only certain packages work with JIT.\n",
    "* `Julia`: [Julia](https://julialang.org/) is an exciting new language that is based entirely around JIT compilation. The fact that the language is built around JIT means that all packages interact nicely with one another while maintaining their JIT capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61672c4a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Numba\n",
    "\n",
    "As mentioned, Numba is a Python package that adds JIT compilation to a subset of the language using the LLVM compiler library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a0ac12",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What works within Numba?\n",
    "\n",
    "* Many Python objects. including: lists, tuples, dictionaries, integers, floats, strings\n",
    "* Python logic, including: `if.. elif.. else`, `while`, `for .. in`, `break`, `continue`\n",
    "* NumPy arrays\n",
    "* Many (but not all!) NumPy functions\n",
    "\n",
    "For more information, read these sections from the documentation\n",
    "\n",
    "* [Supported Python features](https://numba.readthedocs.io/en/stable/reference/pysupported.html)\n",
    "* [Supported NumPy  features](https://numba.readthedocs.io/en/stable/reference/numpysupported.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9c78a7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When to use Numba?\n",
    "\n",
    "* Loops!!!\n",
    "* Can facilitate parallelization (we won't talk about this today)\n",
    "* GPU code generation (we won't talk about this today)\n",
    "* Did we say loops yet?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdd08eb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example\n",
    "\n",
    "Let's begin with the example we described above by writing a function that approximates pi.\n",
    "\n",
    "Imagine that you have the value of $\\pi$ has been lost and that you're tasked with finding it. How would you do it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a80f539",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_pi(n=1_000_000):\n",
    "    \"\"\"\n",
    "    Approximates pi by drawing two random numbers and\n",
    "    determining whether the of the sum of their squares\n",
    "    is less than one (which tells us if the points are\n",
    "    in the upper-right quadrant of the unit circle). The\n",
    "    fraction of draws in the upper-quadrant approximates\n",
    "    the area which we can then multiply by 4 to get the\n",
    "    area of the circle (which is pi since r=1)\n",
    "    \"\"\"\n",
    "    in_circ = 0\n",
    "\n",
    "    # Iterate for many samples\n",
    "    for i in range(n):\n",
    "        # Draw random numbers\n",
    "        x = np.random.random()\n",
    "        y = np.random.random()\n",
    "\n",
    "        if (x**2 + y**2) < 1:\n",
    "            in_circ += 1\n",
    "\n",
    "    return 4 * (in_circ / n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10bd616",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Vanilla Python function\n",
    "calculate_pi(5_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0bd921",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# JIT function\n",
    "calculate_pi_numba = numba.jit(calculate_pi)\n",
    "calculate_pi_numba(5_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c62532",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "calculate_pi_numba(5_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81421444",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Why was the second run faster?\n",
    "\n",
    "Remember the order than JIT works -- The first time it sees a particular function with given inputs, it has to compile the function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2077151",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Pandas?\n",
    "\n",
    "Does Numba work with Pandas?\n",
    "\n",
    "We continue with our example of drawing random numbers to approximate $\\pi$. We will now draw I$ distinct groups of $N$ points and track whether each point was in the circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9467142b",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def fill_dataframe(N, I):\n",
    "    # Create empty dataframe\n",
    "    df = pd.DataFrame(index=np.arange(N), columns=np.arange(I))\n",
    "\n",
    "    for n in range(N):\n",
    "        for i in range(I):\n",
    "            x = np.random.rand()\n",
    "            y = np.random.rand()\n",
    "\n",
    "            df.at[n, i] = int((x**2 + y**2) < 1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20fb952",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Our I approximations of pi\n",
    "N = 1_000\n",
    "I = 10\n",
    "\n",
    "4 * fill_dataframe(N, I).mean(axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de1783e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fill_dataframe_numba = numba.jit(fill_dataframe, nopython=False)\n",
    "\n",
    "fill_dataframe_numba(N, I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b57f41f",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Object mode vs no Python mode**\n",
    "\n",
    "* Object mode: Allows Numba to call out to the Python interpreter if it sees something that it doesn't recognize - The cost is that this is slow and requires Numba to make certain optimization sacrifices\n",
    "* No Python mode: If it sees an object that Numba doesn't recognize, it throws an error. This helps allow Numba make additional optimizations.\n",
    "\n",
    "Numba's default behavior used to be to compile things in \"object\" mode but, recently, they've decided to reverse the default behavior to be no Python mode because it was the main use case (and how they recommend people use it)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72781cbc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Alternate way to fill the DataFrame**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8851fa0a",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "@numba.jit(nopython=True)\n",
    "def simulate_pi_draws(N, I):\n",
    "    pi_out = np.empty((N,  I), dtype=\"int\")\n",
    "\n",
    "    for n in range(N):\n",
    "        for i in range(I):\n",
    "            x = np.random.rand()\n",
    "            y = np.random.rand()\n",
    "\n",
    "            pi_out[n, i] = int((x**2 + y**2) < 1)\n",
    "    \n",
    "    return pi_out\n",
    "\n",
    "\n",
    "def fill_dataframe2(N, I):\n",
    "    pi_draws = simulate_pi_draws(N, I)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        data=pi_draws, index=np.arange(N), columns=np.arange(I)\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b57044c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "4*fill_dataframe(10_000, 25).mean(axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fa9ffb",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "4*fill_dataframe_numba(10_000, 25).mean(axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cf06c2",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "4*fill_dataframe2(10_000, 25).mean(axis=0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c650f04",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Additionally, `numba` makes it easy to parallelize some frequent use cases with the use of `prange`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c91d087",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from numba import prange\n",
    "\n",
    "numba.get_num_threads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8029f406",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "@numba.jit(nopython=True)\n",
    "def evaluate_pi_st(N, I):\n",
    "    pi = np.empty(I)\n",
    "\n",
    "    for i in range(I):\n",
    "        pi_approx = 0.0\n",
    "        for n in range(N):\n",
    "            x = np.random.rand()\n",
    "            y = np.random.rand()\n",
    "\n",
    "            pi_approx += 4*((x**2 + y**2) < 1)/N\n",
    "\n",
    "        pi[i] = pi_approx\n",
    "\n",
    "    return np.mean(pi)\n",
    "\n",
    "evaluate_pi_st(25, 5);\n",
    "\n",
    "\n",
    "@numba.jit(nopython=True, parallel=True)\n",
    "def evaluate_pi_mt(N, I):\n",
    "    pi = np.empty(I)\n",
    "\n",
    "    for i in prange(I):\n",
    "\n",
    "        pi_approx = 0.0\n",
    "        for n in range(N):\n",
    "            x = np.random.rand()\n",
    "            y = np.random.rand()\n",
    "\n",
    "            pi_approx += 4*((x**2 + y**2) < 1)/N\n",
    "\n",
    "        pi[i] = pi_approx\n",
    "\n",
    "    return np.mean(pi)\n",
    "\n",
    "evaluate_pi_mt(25, 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82644847",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "evaluate_pi_st(50_000, 10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490e9c4e",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "evaluate_pi_mt(50_000, 10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97998c6e",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "3.54 / 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7f454d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Numba (GPU)\n",
    "\n",
    "Historically writing code that could run a GPU has been very difficult and required specialized tools.\n",
    "\n",
    "This is becoming less and less true for certain classes of problems. We will talk about some of the tools that make it very easy to leverage your GPU for scientific computing.\n",
    "\n",
    "One note: Using `numba` to write GPU code requires an NVIDIA GPU. NVIDIA has some proprietary tooling called CUDA that `numba` uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aafccf",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60022d44",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![cpu-vs-gpu](cpu-vs-gpu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca3a231",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "CPUs and GPUs are built with different purposes in mind. CPUs are optimized to perform relatively large tasks in serial while GPUs are structured to do many relatively small tasks all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bbdf42",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "gpu = cuda.current_context()\n",
    "\n",
    "gpu.device.name  # I have 4864 cuda cores on my GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27029fa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**CUDA Kernels**\n",
    "\n",
    "The \"small\" tasks that a GPU executes over all of its cores is referred to as a kernel.\n",
    "\n",
    "A kernel takes arrays as inputs and it does not have a return value. This means that the output that we would like from the kernel should be written into one of the arrays.\n",
    "\n",
    "Let's start with a simple example where we add one to whatever value is currently in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c960a4a2",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def increment_by_one(x):\n",
    "    pos = cuda.grid(1)\n",
    "    if pos < x.size:\n",
    "        x[pos] = x[pos] + 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffaf988",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Threads and blocks\n",
    "\n",
    "You might be wondering in the function above what the lines\n",
    "\n",
    "```\n",
    "    pos = cuda.grid(1)\n",
    "    if pos < x.size:\n",
    "       ...\n",
    "```\n",
    "\n",
    "are for.\n",
    "\n",
    "When you do GPU computing the work is broken into blocks of work.\n",
    "\n",
    "Each of these blocks receives a certain number of threads assigned to it and these threads each do a portion of the work. The number of threads per block should be a multiple of 32 (with a maximum of 1024 threads per block) because of the way that the hardware is designed.\n",
    "\n",
    "By default, this function will run on every thread of every block, but this doesn't always make sense because the size of the array might not be equal to `threads_per_block * nblocks` because `threads_per_block` should be a multiple of 32."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b171e1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Choosing a number of threads/blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fbf4df",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test = np.ones(10_000)\n",
    "\n",
    "blocks = 64\n",
    "threads_per_block = (10_000 // 64) + 1\n",
    "\n",
    "for n in range(25):\n",
    "    increment_by_one[blocks, threads_per_block](test)\n",
    "\n",
    "cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7facf033",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b097a20",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Each time we call the function above, it is being passed from the CPU memory, to the GPU memory, and then back.\n",
    "\n",
    "The majority of compute applications are \"memory bound\" rather than \"compute bound\" which means that moving memory quickly enough is usually the binding constraint on speeding up our code.\n",
    "\n",
    "When possible, you should move your array to the GPU and not move it back until you're done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb82bd2",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test = np.ones(10_000)\n",
    "test_cuda = cuda.to_device(test)\n",
    "\n",
    "blocks = 64\n",
    "threads_per_block = (10_000 // 64) + 1\n",
    "\n",
    "for n in range(25):\n",
    "    increment_by_one[blocks, threads_per_block](test_cuda)\n",
    "\n",
    "cuda.synchronize()\n",
    "test_result = test_cuda.copy_to_host()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1542669a",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271b0339",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Back to computing pi\n",
    "\n",
    "We now return to our computing pi example except we do it on the GPU now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3e9aa0",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from numba.cuda.random import create_xoroshiro128p_states, xoroshiro128p_uniform_float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c36b8e",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "@cuda.jit(device=True)\n",
    "def in_circle(x, y):\n",
    "    if (x**2 + y**2) <= 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def compute_pi_kernel(rng_states, iterations, out):\n",
    "    pos = cuda.grid(1)\n",
    "\n",
    "    if pos < out.size:\n",
    "        inside = 0\n",
    "        for i in range(iterations):\n",
    "            x = xoroshiro128p_uniform_float32(rng_states, pos)\n",
    "            y = xoroshiro128p_uniform_float32(rng_states, pos)\n",
    "\n",
    "            inside += in_circle(x, y)\n",
    "\n",
    "        out[pos] = 4.0 * (inside / iterations)\n",
    "\n",
    "\n",
    "def compute_pi_on_gpu(N, I):\n",
    "    # Threads/blocks\n",
    "    threads_per_block = 256\n",
    "    blocks = (I//threads_per_block + 1)\n",
    "\n",
    "    # Set up RNG\n",
    "    rng_states = create_xoroshiro128p_states(I, seed=20220116)\n",
    "\n",
    "    out = cuda.device_array(I)\n",
    "    compute_pi_kernel[blocks, threads_per_block](rng_states, N, out)\n",
    "    cuda.synchronize()\n",
    "\n",
    "    return np.mean(out.copy_to_host())\n",
    "\n",
    "# Make sure things get compiled\n",
    "compute_pi_on_gpu(50, 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa40b1cf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Comparing the speeds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388fb501",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "N = 50_000\n",
    "I = 50_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9444988c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "evaluate_pi_st(N, I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0faa7c3",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "evaluate_pi_mt(N, I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa23b34a",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "compute_pi_on_gpu(N, I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d37710f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
